\chapter{Алгоритмы}
Подход к решению задачи:
\begin{enumerate}
 \item запустить систему без модификаций;
 \item найти самое слабое место в системе;
 \item принять меры по его устранению;
 \item перейти к пункту \textit{2}.
\end{enumerate}
\section{Ранжирование}
При работе системы в стандартной конфигурации было замечено, что только из 10\% скачиваемых веб-страниц выделяются документы. Это происходит из-за неоптимального упорядочивания ссылок из \textit{сrawldb}.

Определение порядка выбора URL для скачивания существенно сказывается на эффективности работы робота.\cite{crawl}\cite{focused}\cite{opic} Порядок неважен только в том случае, если робот нацелен на одноразовое скачивание всего Web, и нагрузка создаваемеая роботом на целевые сайты не важна, так как тогда каждая известная URL будет в конце концов загружена. Однако большинство роботов не способно посетить каждый URL по трем основным причинам:
\begin{itemize}
 \item Ограничение по ресурсам --- размер хранилища, ширина канала, CPU time для обработки страниц.
 \item Сбор документов занимает время, поэтому в определенный момент робот вынужден заново посещать некоторые страницы для нахождения изменений.
 \item Динамическое создание страниц --- сейчас большинство сайтов разадают не статический контент, а создают его динамически при помощи скриптов обрабатывающих URL и возвращающих результат, таким образом количество страниц на сайте может быть неограницено.
\end{itemize}

Во всех остальных случаях важно что бы робот сначала посещал ``важные'' страницы. Ранжирование отвечает за определенеие того, на сколько URL ``важна''. В стандартной конфигурации Nutch для выбора ссылок используется \textit{OPIC Score}\cite{opic}.
\subsection{OPIC}
